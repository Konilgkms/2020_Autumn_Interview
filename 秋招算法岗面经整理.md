### 华为 - 算法工程师实习
#### 技术面（60分钟）
- 介绍天池的两个比赛细节，重点询问了如何构造特征
- 介绍word2vec的原理
- 叙述xgboost和lightgbm的区别
- 介绍LSTM及其变种
- 算法题
- 对什么样的工作感兴趣
- 反问环节

#### 业务主管面（40分钟）
- 询问简历上的一个比赛，问得很细，面试官比较在意推广性
- 在实验室的代码量如何
- 反问环节

### 百度 - 商业场景营销研发部
#### 技术1面（60分钟）
- 自我介绍
- 深挖项目，从数据规模、特征、指标、目前使用的模型方法详细介绍
- 关于项目的指标，提到自己想的和交付方要求的指标不同，提了自己的想法，面试官表示赞同，也一起讨论了原因
- 介绍了一下论文，因为是本科发的比较水的论文，所以稍微总结了一下
- 深挖比赛，选择模型考虑哪些因素
- 介绍lgb和xgb的区别
- 挖了一下几个比赛的细节，还说其中一个操作他们也有类似的
- 如何处理样本不均衡问题，并介绍公司如何处理
- 聊了一下实习
- 问计算机相关课程学的怎么样，语言学的怎么样，没有深挖
- 还面试了什么公司
- 场景题，类似基数排序，先是问所有排序中时间复杂度最坏情况最好的是什么，然后结合场景给出最快的方案（开大数组），面试官问了如何优化内存（位计数），然后给我介绍了公司如何继续优化的方向

#### 技术2面（60分钟）
- 手撕代码，场景题：给一个文件，里面存储着一个类别ID以及该类别的父类别ID，要求写函数处理文件，并能够根据查询的类别ID输出其所有子类别的ID，个人理解是把文件构造成多叉树，根据输入的节点输出其所有子节点
- C++结构体初始化时，什么时候不写构造函数会报错
- C++的vector底层实现
- C++的sort底层实现
- 介绍实习
- 介绍比赛
- 如何处理过拟合和欠拟合
- 对L1和L2正则化的理解
- 介绍一下SVM，遇到线性不可分怎么办，核函数有什么特点
- 场景题，百度有海量的搜索词记录，返回TopK个高频词
- 反问

### 腾讯 - 机器学习
#### 技术1面（55分钟）
- 一根绳子分成三段，能围成三角形的概率
- 深挖比赛，截至目前给我感觉比赛挖得最深的
- 介绍一下xgb
- xgb的boosting如何体现，有什么特殊含义
- xgb能否处理离散特征，为什么，如果要用怎么处理
- lgb能否处理，模型做了哪些操作
- 给一个训练样本，其中有一个离散特征，取值有100W维，怎么解决
- xgb的分类树也是用残差吗，不是的话是什么
- 什么是似然估计，什么是先验概率/后验概率，举例说明
- 介绍word2vec，训练得到的word2vec的本质
- 代码题：给个矩阵，0代表可以通行，1代表死路，求一条从左上到右下的路径

### 美团 - 到店事业群
#### 技术面（70分钟）
- 自我介绍，把自己的项目、比赛、论文、实习过一遍
- 一个推荐的比赛，如何做召回、粗排、精排的，深挖了一下比赛的操作，问的比较细
- 介绍xgb和lgb，改进了什么
- 推荐问题中的几种排序
- 是否了解过一些深度学习的排序方法
- 介绍一下LSTM
- LSTM解决了RNN的什么问题，如何解决
- 代码题：给定一个目标值M的数组，返回数组是否存在和为M子集
- 概率题：N枚真硬币是一面图案一面字，M枚假硬币是两面图案，选了一枚抛K次都是图案，问是真硬币的概率——贝叶斯
- 智力题：25匹马，5个赛道，最多几次可以知道前三名
- base优先级
- 是否可以提前实习
- 反问环节

### 云从科技 - 数据挖掘算法工程师
#### 技术面（50分钟）
- 自我介绍，介绍到一半被打断了...
- 本科与研究生成绩排名
- 挑一个项目介绍，现在回头做会如何优化
- RF与XGB的区别，Gini的物理含义
- C++指针与引用的区别
- Python列表与元祖的区别
- 代码题：有序数组寻找目标值最后出现的位置
- 从海量数据中寻找频数前1000的数据
